{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "### Kolesov Aleksandr (M05-004a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data for the experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_breast_cancer( return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 626,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =  train_test_split(X,y,train_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((170, 30), (399, 30), (170,), (399,))"
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we get our $\\textbf{X}$ $\\in \\mathbb{R}^{m x n}$, where m = 170 and n = 30. Ath the same time $y \\in \\{+- 1\\}^{m}$ This matrix is data for the training of the model.\n",
    "\n",
    "\n",
    "Moreover, this lab is supported by PyTorch framework , hence one should transform all numpy arrays to torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_train = np.where(y_train == 0)\n",
    "mask_test = np.where(y_test == 0)\n",
    "y_train[mask_train] = -1\n",
    "y_test[mask_test] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train).float()\n",
    "y_train = torch.tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor(X_test).float()\n",
    "y_test = torch.tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our likelihood model is $p(y|x, w) = \\prod_{j=1}^{m} \\sigma (y_{j}w^{T}x_{j})$, the following class constitutes such probabilistic model with its methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Likelihood_model:\n",
    "    \n",
    "    def __init__(self, weights):\n",
    "        \n",
    "        \"\"\"\n",
    "        weights : torch.tensor of shape 1 x n\n",
    "        \n",
    "        \"\"\"\n",
    "        self.weights = weights\n",
    "        \n",
    "    def get_weights(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        return a current weight of a model\n",
    "        \n",
    "        return : torch.tensor of shape 1 x n\n",
    "        \"\"\"\n",
    "        return self.weights\n",
    "        \n",
    "    def compute_likelihood(self, y, x):\n",
    "        \n",
    "        \"\"\"\n",
    "        y : torch.tensor of shape m x 1\n",
    "        x : torch.tensor of shape m x n\n",
    "        w : torch.tensor of shape 1 x n\n",
    "        \n",
    "        returns : torch.tensor of shape 1 x 1  (value)\n",
    "        \n",
    "        \"\"\"\n",
    "        x = x.reshape(-1, self.weights.shape[1] )\n",
    "        y = y.reshape(-1, 1)\n",
    "         \n",
    "        term = torch.stack( [-y * (self.weights@x.T).T] , dim = 0 )\n",
    "         \n",
    "        term = term.squeeze()\n",
    "         \n",
    "        return  1 / (1 + torch.exp(term)) , torch.prod(  1 / (1 + torch.exp(term))  , dim = 0)\n",
    "\n",
    "\n",
    "    def first_derivative(self,y,x):\n",
    "        \n",
    "        \"\"\"\n",
    "        The derivative of likelihood by weight\n",
    "        \n",
    "        y : torch.tensor of shape m x 1\n",
    "        x : torch.tensor of shape m x n\n",
    "        \n",
    "        returns: torch.tensor of shape n \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        likelihood,_ = self.compute_likelihood(y, x) # torch.tensor of shape  m\n",
    "        \n",
    "       \n",
    "         \n",
    "        y = y.reshape(-1,1)\n",
    "        derivative = torch.stack([-x*y], dim = 0).squeeze() # torch.tensor of shape m x n\n",
    "        \n",
    "            \n",
    "        current_derivative = [0]*((likelihood.shape[0]))\n",
    "        result = torch.zeros_like(derivative[-1])\n",
    "        \n",
    "        for i in range(likelihood.shape[0]):\n",
    "            current_derivative[i] = - derivative[i] + (1 + (- y[i]* (self.weights@x[i].T).T)) \n",
    "             \n",
    "            \n",
    "        \n",
    "        for i in range(len(current_derivative)):\n",
    "            result += current_derivative[i]\n",
    "            \n",
    "         \n",
    "            \n",
    "         \n",
    "        return result\n",
    "        \n",
    "    def second_derivative(self,y,x):\n",
    "        \n",
    "        \"\"\"\n",
    "        y: torch.tensor of shape 1 x m\n",
    "        x: torch.tensor of shape n x m\n",
    "        \n",
    "        \"\"\"\n",
    "        likelihood = self.compute_likelihood(y, x)\n",
    "        derivative = (-x @ y.T).pow(2)\n",
    "        return derivative * likelihood *( 1 - likelihood)*(1 - 2*likelihood)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prior Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prior:\n",
    "    \n",
    "    def __init__(self, variances):\n",
    "        \n",
    "        \"\"\"\n",
    "        Probability distibution of prior\n",
    "        n - dimensional with diagonal covariance matrix\n",
    "        \n",
    "        variances: torch.tensor of shape  n : (torch.ones(5))\n",
    "        \n",
    "        \"\"\"\n",
    "        self.variances = variances\n",
    "        self.locs      = torch.zeros(variances.shape)\n",
    "        normal         = torch.distributions.normal.Normal(self.locs, self.variances )\n",
    "        self.distribution = torch.distributions.independent.Independent(normal , 1)\n",
    "        \n",
    "        \n",
    "    def log_probability(self, w):\n",
    "        \n",
    "        \"\"\"\n",
    "        log_probability at current point x\n",
    "        \n",
    "        w : torch.tensor of shape 1 x n\n",
    "        returns : torch.tensor of shape 1 x 1\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        return self.distribution.log_prob(w)\n",
    "    \n",
    "    \n",
    "    def sample(self, n_counts):\n",
    "        \n",
    "        \"\"\"\n",
    "        sample element from prior distribution\n",
    "        \n",
    "        n_counts :  num samples that are desirable to sample\n",
    "        returns :   torch.tensor of shape n_counts x n\n",
    "        \n",
    "        \"\"\"\n",
    "        return self.distribution.sample(torch.tensor([n_counts]))\n",
    "    \n",
    "    def first_derivative(self, w):\n",
    "        \n",
    "        \"\"\"\n",
    "        The derivative of log-density by weight with fixed A\n",
    "        \n",
    "        w: torch.tensor of shape 1 x n\n",
    "        \n",
    "        returns: torch.tensor of shape  n x 1\n",
    "        \"\"\"\n",
    "        return torch.diag(self.variances)@w.T\n",
    "    \n",
    "    def second_derivative(self, w):\n",
    "        return 0.5*(torch.diag(self.variances) - torch.diag(self.variances)@w.T@w@torch.diag(self.variances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate likelihood of our model and know prior distribution. Then , one can pay our attention to Bayes theorem:\n",
    "\n",
    "- $p(y,w|X, A) = p(y|X,w) p(w|A) $   =   $\\prod_{j=1}^{n} \\sigma(y_{j}w^{T} x_{j})$ $\\mathcal{N} (0,A^{-1})$\n",
    "\n",
    "It is worth noticing that $A = diag(\\alpha)$. \n",
    "\n",
    "- One would like to select such parameters of prioir distribution which can naximize evidence \n",
    "\n",
    "$$ A^{*} = \\arg \\max_{A} \\int p(y|X,w) p(w|A) dw $$\n",
    "\n",
    "Let $Q(w) = p(y|X,w) p(w|A)$\n",
    "\n",
    "Since we cannot integrate, then one can use Taylor expansion near Maximum posterior point(MAP)\n",
    "\n",
    "$$ \\log Q(w) \\sim \\log Q(w_{MAP}) + \\frac{1}{2}(w - w_{MAP})^{T} \\nabla \\nabla \\log Q(w_{MAP})(w -w_{MAP}) $$\n",
    "\n",
    "However, MAP point depends on A, though A is not optimized.\n",
    "\n",
    "Then , Algorithm:\n",
    "\n",
    "- 1. calculate W_{MAP} through fixed A \n",
    "- 2. Optimize the functional of Laplace's approximation through parameters of A "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ p(y, w|X, A) = \\prod_{j=1}^{m} \\sigma(y_{j} w^{T} x_{j}) \\frac{\\sqrt{detA}}{(2 \\pi)^{n/2}}e^{-\\frac{1}{2}w^{T}Aw}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculation w_MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First derivative of Q(w) to find out w_MAP\n",
    "\n",
    "$$ \\nabla_{w} Q(w)  = \\nabla_{w} (p(y|X,w)p(w|A)) = 0$$\n",
    "\n",
    "First of all, we find the point, where the first dervative of Q is equal to zero - that is w_MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undoubtedly, we consider logarithm of this function Q and in the above classes, methods of first derivative takes in mind this fact\n",
    "\n",
    "$$ \\nabla_{w} \\log Q(w) = \\nabla_{w} \\log p(w|A) + \\nabla_{w} (\\log \\sigma_{1} + ... + \\log \\sigma_{m}) ->  \\min_{w}$$\n",
    "\n",
    "In other words, I want to select such parameters that this first derivative of the function equals to zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-661-987765d9c3bb>:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for iteration in tqdm_notebook(range(num_iterations)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84efd3908a934260a91ad284be1097a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = torch.rand(1,30)\n",
    "init_weights = weights.clone()\n",
    "weights = torch.nn.Parameter(weights, requires_grad = True)\n",
    "\n",
    "optimizer = torch.optim.SGD([weights], lr=1e-4,  weight_decay=1e-6, momentum=0.9, nesterov=True )\n",
    "like_model = Likelihood_model(weights)\n",
    "prior = Prior(torch.ones(30))\n",
    "\n",
    "num_iterations = 50\n",
    "\n",
    "\n",
    "history = [0]*(num_iterations)\n",
    " \n",
    "for iteration in tqdm_notebook(range(num_iterations)):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    log_model_derivative = like_model.first_derivative(y_train.unsqueeze(0), X_train).unsqueeze(-1) # with gradient torch.Size([30,1])\n",
    "    \n",
    "    current_weights = like_model.get_weights()\n",
    "    log_prior_derivative = prior.first_derivative(current_weights) # with gradient torch.Size([30,1])\n",
    "     \n",
    "    loss_vector =  ( log_model_derivative +  log_prior_derivative) # with gradient  torch.Size ([30,1])\n",
    "    \n",
    "    (torch.sum(loss_vector, dim=0)).backward()\n",
    "    history[iteration] =  torch.sum(loss_vector,dim=0).item() \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(50),history)\n",
    "plt.xlabel(\"num iterations\")\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly, optimized weights of our model one can move on to the following step, to tune parameters of prior distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_map = weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Finding optimal parameters of A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will learn diagonal elements of covariance matrix and weights of the model simultaneously be the abovemetioned formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-685-3d292bf8b4fe>:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for iteration in tqdm_notebook(range(num_iterations)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e32c8f14de7e4862860beb51aff88586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights = torch.rand(1,30)\n",
    "variances = 30*torch.ones(30)\n",
    "init_weights = weights.clone()\n",
    "weights = torch.nn.Parameter(weights, requires_grad = True)\n",
    "variances = torch.nn.Parameter(variances, requires_grad = True)\n",
    "\n",
    "optimizer = torch.optim.SGD([weights, variances], lr=1e-1,  weight_decay=1e-6, momentum=0.9, nesterov=True )\n",
    "like_model = Likelihood_model(weights)\n",
    "prior = Prior(variances)\n",
    "\n",
    "num_iterations = 1\n",
    "\n",
    "\n",
    "history = [0]*(num_iterations)\n",
    " \n",
    "for iteration in tqdm_notebook(range(num_iterations)):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    log_model = like_model.compute_likelihood(y_train.unsqueeze(0), X_train)[-1]\n",
    "    \n",
    "    current_weights = like_model.get_weights()\n",
    "    log_prior = prior.log_probability(current_weights).squeeze()\n",
    "    \n",
    "    \n",
    "    \n",
    "    difference = weights - weights_map\n",
    "    #log_model_derivative = like_model.second_derivative(y_train.unsqueeze(0), X_train).unsqueeze(-1) # with gradient torch.Size([30,30])\n",
    "    \n",
    "     \n",
    "    log_prior_derivative = prior.second_derivative(current_weights) # with gradient torch.Size([30,30])\n",
    "    second_derivative = log_prior_derivative # + log_model_derivative\n",
    "    \n",
    "    loss = log_model + log_prior + 0.5*difference@second_derivative@difference.T\n",
    "    \n",
    "    loss.backward()\n",
    "    history[iteration] = loss.item() \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-8.0368e+06, -1.9374e+07, -1.9204e+07,  2.2394e+08, -3.5310e+04,\n",
       "         1.3393e+04,  8.3734e+03,  2.7870e+04, -1.3340e+05, -6.6861e+04,\n",
       "         2.3807e+04, -2.2120e+06,  1.3035e+05,  3.5273e+07, -3.5776e+03,\n",
       "        -5.7271e+03,  6.1341e+03, -4.5109e+02, -6.8206e+03,  2.1489e+03,\n",
       "        -4.6446e+06, -1.9914e+07, -2.3927e+06,  6.9721e+07, -1.2142e+05,\n",
       "         3.9885e+04,  9.0345e+04,  1.0181e+05, -1.7248e+05, -2.2190e+04])"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variances.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x129644a00>"
      ]
     },
     "execution_count": 694,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS4AAAEDCAYAAACLcumrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAATyElEQVR4nO3df4wc9X3G8fdjYxdqKCFyIK4xgSJLDUkVQJYJpaqcpmmNE8lBDRVUSmgUyUkEFUiRWoSqgCpVQlUgbUQKMsUCKgKigiRW4gQQRTJRG4JxHX7ETbEogcOuHYOKoUEF3z39Y+aa29273bm7vZ2Z8/OSRrc7Mzvz8YY8+s53vvNd2SYiok2W1F1ARMRsJbgionUSXBHROgmuiGidBFdEtE6CKyJaJ8EVcQyStE3SIUnPVtj3DEmPSfo3SU9L2jSKGvtJcEUcm+4ENlbc9y+B+22fB1wG/P1CFVVVgiviGGR7J/Da1HWSzpb0fUlPSXpc0m9O7g78Wvn6ZGD/CEud1nF1FxARjbEV+ILt5yVdQNGy+j3gBuBhSX8GrAB+v74SCwmuiEDSicBvA/8kaXL1r5R/LwfutH2TpAuBf5T0QdsTNZQKJLgiorAE+G/b506z7XOU/WG2/1XS8cBK4NDoyuuUPq6IwPYR4D8lXQqgwofKzS8BHy3Xvx84Hvh5LYWWlNkhIo49ku4FNlC0nA4C1wP/DNwKrAKWAffZ/itJ5wC3AydSdNT/ue2H66h7UoIrIlonl4oR0Toj7ZxfvuR4n7DkpOk3LkmGRszXW+NHeHv8LQ3ec2Z/+JEVfvW18Ur7PvX0/z5ku+pA1qGZV3BJ2gj8HbAU+AfbN/bb/4QlJ3HhyZdMf6wVvzqfUiIC+Jf/unfex3j1tXF+9NAZlfZduur5lfM+4RzMObgkLQW+DnwMGAOelLTd9k+GVVxEjJ6BCWobolXJfFpc64F9tl8AkHQfsBlIcEW0mDHvuNqlYl3mE1yrgZenvB8DLujeSdIWYAvA8UtOnMfpImJUFnOLa7oOwJ6xFba3UjwDxcnHvSdjLyIazpjxhg+Tmk9wjQFrprw/nQY8NR4R8zfR2wZplPkE15PAWklnAa9QzNPzJ30/sWTJjHcPj4690vejx52+ek5FRsTsGBhfrMFl+6ikq4CHKIZDbLP93NAqi4jaLOYWF7Z3ADuGVEtENICBdxZxH1dELELGi/dSMSIWKcN4s3MrwRURnYqR882W4IqILmJ82mGazZHgiogORed8gquSQeO0+o3zyhiviOEpxnEluCKiZSbS4oqINkmLKyJax4jxhs/q3uzqIqIWE1alZRBJayQ9JmmvpOckXT3NPpL0NUn7JD0t6fxBx02LKyI6GPG2lw7rcEeBL9neLekk4ClJj3TNlHwxsLZcLqD4ibSeuf2mSosrIjoUA1CXVFoGHss+YHt3+foNYC/FJKRTbQbuduGHwLskrep33Na0uPoNefjuj74747aPr//4QpQTsajNonN+paRdU95vLScP7SHpTOA84ImuTdPNprwaODDTSVsTXBExGrYYd+WLscO21w3aSdKJwAPANbaPdG+erox+x0twRUSPiSEOh5C0jCK07rH94DS7zHo25QRXRHQoOueHEw2SBNwB7LV98wy7bQeuKn8p7ALgddszXiZCgisiukx2zg/JRcCngWck7SnXXQecAWD7NorJSDcB+4BfAJ8ddNAEV0T0GB/SIz+2f8D0fVhT9zFw5WyOm+CKiA5tGDm/KIIrQx4ihmui+l3FWiyK4IqI4Skesk5wRUSLGPHO8B75WRAJrojoYDObAai1SHBFRBcNdQDqQkhwRUQHkxZXRLRQOucjolVMtUkC6zSv4JL0IvAGMA4crfKUeEQ0W/HzZM1u0wyjuo/YPjyE40REI+QHYSOiZUzzR87PtzoDD0t6StKW6XaQtEXSLkm73p54a56ni4hRGC9bXYOWusy3xXWR7f2STgUekfTvtndO3aGcxnUrwMnLT+s7q2FE1M9W41tc8wou2/vLv4ckfRNYD+zs/6mIaLKic77Zj/zMOVYlrSh/bghJK4A/AJ4dVmERUZdizvkqS13m0+I6DfhmMTMrxwHfsP39oVQVEbUpOucX6V1F2y8AHxpiLRHREBk5HxGtsuhHzkfE4jTEH8tYEAmuiOhgwzsTCa6IaJHiUjHBFREtk2cVI6JVFvVwiIhYrHKpGBEtlDnnI6JViruKzX5WMcEVER0yADUiWimXihHRKrmrGBGtlLuKEdEqtjia4IqItsmlYkS0Svq4IqKVmh5czb6QjYiRmxzHVWUZRNI2SYckTft7FJI2SHpd0p5y+XKVGtPiiogeQxzHdSdwC3B3n30et/2J2Rw0wRURHWw4OqSJBG3vlHTmUA42RS4VI6LHLC4VV07+Un25TPuL9gNcKOnHkr4n6QNVPpAWV0R0mOWziodtr5vH6XYD77P9pqRNwLeAtYM+lBZXRPSwVWmZ/3l8xPab5esdwDJJKwd9Li2uiOgxqoesJb0XOGjbktZTNKZeHfS5BFdEdLCHN45L0r3ABoq+sDHgemBZcR7fBnwK+KKko8BbwGW2Pei4Ca6I6CLGh3dX8fIB22+hGC4xKwmuiOgxjP6rhTQwVqcb+Srp3ZIekfR8+feUhS0zIkZl8lnFYYycXyhV2oN3Ahu71l0LPGp7LfBo+T4iFgMX/VxVlroMDC7bO4HXulZvBu4qX98FfHK4ZUVEnSZQpaUuc+3jOs32AQDbBySdOtOO5UjaLQDHLz1pjqeLiFHxEDvnF8qCV2d7q+11ttctX3LCQp8uIoag9ZeKMzgoaRVA+ffQ8EqKiLqNauT8XM01uLYDV5SvrwC+PZxyIqJuRWuq2cE1sI9rhpGvNwL3S/oc8BJw6UIWGaXx8Zm3LW32Lw9HuzR9BtSBwdVn5OtHh1xLRDREnf1XVWTkfER0MGKi4XcVE1wR0aPhDa4EV0R0cfOfVUxwRUSvhje5ElwR0SMtrhiefkMe1Oc/tKbfIopGMTAxkeCKiDYxkBZXRLRN0xvpCa6I6JXgioh2qfc5xCoSXBHRKy2uiGgVg3NXMUaiT2/q//zWr/f96Ipn9g+7mmi9BFdEtE0uFSOidRJcEdEqGYAaEW2UAagR0T65qxgRbaO0uCKiVUw656N+GacVs6N0zkdEC6XFFRGtM1F3Af0luCKiU8ZxRUQb5a5iRLRPw4Or2T9XGxGtJmmbpEOSnp1huyR9TdI+SU9LOr/KcRNcEdFDrrZUcCewsc/2i4G15bIFuLXKQQcG13SJKekGSa9I2lMum6qcLCJawBSP/FRZBh3K3gm81meXzcDdLvwQeJekVYOOW6XFdSfTJ+ZXbZ9bLjsqHCci2sIVF1gpadeUZcssz7QaeHnK+7FyXV8DO+dt75R05iyLiYgWm8VdxcO2183nVNOsG3j2+fRxXVV2pm2TdMqMVUlbJtP47Ym35nG6iBiZ6i2u+RoD1kx5fzow8Bm1uQbXrcDZwLnAAeCmmXa0vdX2Otvrli85YY6ni4iRGl1wbQc+U95d/DDwuu0Dgz40p3Fctg9OvpZ0O/CduRwnIppnFncMBx9LuhfYQNEXNgZcDywDsH0bsAPYBOwDfgF8tspx5xRcklZNScVLgGnHaERESw1pIkHblw/YbuDK2R53YHDNkJgbJJ1L0Vh8Efj8bE8cEc3V+kd+ZkjMOxaglohoirYHV0QcY4bYx7VQElwR0SvBFRFto4ZPJJiHrCOiddLiioheuVSMiFZJ53xEtFKCKyJaJ8EVEW0imn9XMcEVEZ3SxxURrZTgiojWSXBFRNvkUjEi2ifBFRGt4txVjIg2SosrItomfVwR0T4JroholeH99NiCSXBFRAeRS8WIaKEEV0S0T4IrIlonwRURrZLZISKilRJcEdE2eeQnYoj8zjt9t2vZshFVsrg1/VJx4O8qSloj6TFJeyU9J+nqcv27JT0i6fny7ykLX25ELDjPYqlJlR+EPQp8yfb7gQ8DV0o6B7gWeNT2WuDR8n1ELAZtDy7bB2zvLl+/AewFVgObgbvK3e4CPrlANUbECE2OnK+y1GVWfVySzgTOA54ATrN9AIpwk3TqDJ/ZAmwBOH7pSfMqNiJGQxPN7uSqcqkIgKQTgQeAa2wfqfo521ttr7O9bvmSE+ZSY0SM0iLp40LSMorQusf2g+Xqg5JWldtXAYcWpsSIGLWmXypWuaso4A5gr+2bp2zaDlxRvr4C+Pbwy4uIWgyxxSVpo6SfStonqecmnqQNkl6XtKdcvjzomFX6uC4CPg08I2lPue464EbgfkmfA14CLq32z4iYu0HjtI6OvTLjtuNOXz3schatYbWmJC0Fvg58DBgDnpS03fZPunZ93PYnqh53YHDZ/gHFjYbpfLTqiSKiRYZ3Gbge2Gf7BQBJ91GMSOgOrlmp3DkfEceI8ld+qizASkm7pixbuo62Gnh5yvuxcl23CyX9WNL3JH1gUIl55CciOsxyBtTDttcNOFy37qPvBt5n+01Jm4BvAWv7nTQtrojoZVdbBhsD1kx5fzqwv/NUPmL7zfL1DmCZpJX9DprgiogeQxwO8SSwVtJZkpYDl1GMSPjluaT3lqMXkLSeIpde7XfQXCpGRKchDi61fVTSVcBDwFJgm+3nJH2h3H4b8Cngi5KOAm8Bl9n9m3MJrlhU+g55GB+fedvSpcMvpsWGOR9Xefm3o2vdbVNe3wLcMptjJrgiokcmEoyIdjFVO95rk+CKiB5NnwE1wRURvRJcEdEmsxyAWosEV0R0shs/kWCCK44dfYY8jP3R+2bcdvoDP1uIapqt2bmV4IqIXrlUjIh2MZBLxYhonWbnVoIrInrlUjEiWid3FSOiXWr+6bEqElwRHKNDHmZQDEBtdnIluCKiV2aHiIi2SYsrItolfVwR0T55VjEi2iiXihHRKs7UzRHRRg1vcQ38XUVJayQ9JmmvpOckXV2uv0HSK5L2lMumhS83IkbCFZeaVGlxHQW+ZHu3pJOApyQ9Um77qu2vLFx5EVEHTTT7WnFgcNk+ABwoX78haS/Q58frIqLVTOMHoA68VJxK0pnAecAT5aqrJD0taZukU2b4zBZJuyTtenvirflVGxELThi52lKXysEl6UTgAeAa20eAW4GzgXMpWmQ3Tfc521ttr7O9bvmSE+ZfcUQsPLvaUpNKdxUlLaMIrXtsPwhg++CU7bcD31mQCiNi9BbBXUUBdwB7bd88Zf2qKbtdAjw7/PIiYuQm+7iqLDWp0uK6CPg08IykPeW664DLJZ1L8c98Efj8AtQX0W7SzNsa3KpZDHcVf0AxRU+3HcMvJyLqV2//VRUZOR8RnUyCKyJaqNlXigmuiOiViQQjon0SXBHRKjaMN/taMcEVsZD6tVyaPFSi7vMPMKtnFSPiGDHER34kbZT0U0n7JF07zXZJ+lq5/WlJ5w86ZoIrIjoZmHC1ZQBJS4GvAxcD51AMXD+na7eLgbXlsoXiOei+ElwR0cXgiWrLYOuBfbZfsP02cB+wuWufzcDdLvwQeFfXI4U9ElwR0ckUnfNVFlg5OW1VuWzpOtpq4OUp78fonc+vyj4d0jkfEb2qd84ftr2uz/bp7kB0H7zKPh0SXBHRa3h3FceANVPenw7sn8M+HXKpGFGXBk7QVxY2zLuKTwJrJZ0laTlwGbC9a5/twGfKu4sfBl4vp4yfUVpcEdHJwJCmtbF9VNJVwEPAUmCb7eckfaHcfhvFTDObgH3AL4DPDjpugisieg2x1Wd7B13TYJWBNfnawJWzOWaCKyK65JGfiGgbg6uN0apNgisielUYFV+nBFdE9Kr9zmZ/Ca6I6GQP7a7iQklwRUSvtLgiol2Mx8frLqKvBFdEdJqc1qbBElwR0SvDISKiTQw4La6IaBU7La6IaJ+md87LI7ztKennwM+mrFoJHB5ZAYOlnv6aVg80r6a663mf7ffM5wCSvk/x76jisO2N8znfXIw0uHpOLu0aMHviSKWe/ppWDzSvpqbVs1hlIsGIaJ0EV0S0Tt3BtbXm83dLPf01rR5oXk1Nq2dRqrWPKyJiLupucUVEzFqCKyJap5bgkrRR0k8l7ZN0bR01dNXzoqRnJO2RtKumGrZJOiTp2Snr3i3pEUnPl39PqbmeGyS9Un5PeyRtGmE9ayQ9JmmvpOckXV2ur+U76lNPbd/RsWTkfVySlgL/AXyM4ocgnwQut/2TkRbSWdOLwDrbtQ0clPS7wJvA3bY/WK77G+A12zeWAX+K7b+osZ4bgDdtf2UUNXTVswpYZXu3pJOAp4BPAn9KDd9Rn3r+mJq+o2NJHS2u9cA+2y/Yfhu4D9hcQx2NYnsn8FrX6s3AXeXruyj+j1FnPbWxfcD27vL1G8BeYDU1fUd96okRqCO4VgMvT3k/Rv3/gxt4WNJTkrbUXMtUp03+om/599Sa6wG4StLT5aXkyC5dp5J0JnAe8AQN+I666oEGfEeLXR3BpWnW1T0m4yLb5wMXA1eWl0nR61bgbOBc4ABw06gLkHQi8ABwje0joz5/hXpq/46OBXUE1xiwZsr704H9NdTx/2zvL/8eAr5JcTnbBAfLvpTJPpVDdRZj+6DtcRc/unc7I/6eJC2jCIl7bD9Yrq7tO5qunrq/o2NFHcH1JLBW0lmSlgOXAdtrqAMASSvKzlUkrQD+AHi2/6dGZjtwRfn6CuDbNdYyGQyTLmGE35MkAXcAe23fPGVTLd/RTPXU+R0dS2oZOV/eIv5bYCmwzfZfj7yIX9byGxStLCjmJ/tGHfVIuhfYQDGdyEHgeuBbwP3AGcBLwKW2R9JhPkM9GygugQy8CHx+sn9pBPX8DvA48AwwOcvddRT9SiP/jvrUczk1fUfHkjzyExGtk5HzEdE6Ca6IaJ0EV0S0ToIrIlonwRURrZPgiojWSXBFROv8H4UynmV/JvxVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(torch.diag(variances.detach()).numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth noticing,that I didn't manage to outperform normal analysis due to nan exploison when claculate likelihood of model, that is why necessary I should pay my attention to LogSumExp trick to repeat this work again and get better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
